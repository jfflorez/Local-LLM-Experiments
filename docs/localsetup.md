## Get Started

- Build llama.cpp
- Download models
- Run experiments

### 1. Clone the repository with submodules
```bash
git clone --recurse-submodules https://github.com/jfflorez/Local-LLM-Insights.git
cd Local-LLM-Insights
```
